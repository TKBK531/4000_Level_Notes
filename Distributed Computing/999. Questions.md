
[[Distributed Guide]]

## [[101. MapReduce]]

#### 🔢 **1. Scenario: Counting Hashtags in Tweets**

**Scenario:** You’re working with a dataset containing millions of tweets. Your goal is to count how many times each hashtag appears.

**Question:** How would you design a MapReduce job for this task? Explain the role of Map, Shuffle, and Reduce in your solution.

**Answer:**

- **Map phase:** For each tweet, extract all hashtags and emit (hashtag, 1) 📥.
    
- **Shuffle phase:** Group all values by hashtag (e.g., #AI → [1, 1, 1, 1, …]) 🔀.
    
- **Reduce phase:** Sum the counts for each hashtag → emit (#AI, 47329) ➕.
    

👉 **Optimization tip:** Use a combiner to partially sum up counts before sending them over the network.

---

#### 📚 **2. Scenario: Building a Search Index (Inverted Index)**

**Scenario:** You have a corpus of web pages and want to build an inverted index that maps each word to the list of documents it appears in.

**Question:** Explain how MapReduce can be used to build the inverted index.

**Answer:**

- **Map phase:** For each document, emit (word, documentID) 📝.
    
- **Shuffle phase:** Group values by word → (word → [doc1, doc2, doc5]) 🔀.
    
- **Reduce phase:** Deduplicate and sort document IDs, then emit final (word, [docIDs]) 📚.
    

✅ This allows fast lookup of documents containing a keyword!

---

#### 🧾 **3. Scenario: Log Analysis**

**Scenario:** Your company logs all website traffic. You want to find the number of visits per country per day.

**Question:** How would you apply MapReduce to solve this?

**Answer:**

- **Map phase:** For each log entry, extract (country, date) and emit ((country, date), 1) 🌍📅.
    
- **Shuffle phase:** Group by (country, date).
    
- **Reduce phase:** Count entries per key → emit ((country, date), total_visits) 🧮.
    

📦 You could also use a partitioning function to ensure all logs for the same country go to the same reducer.

---

#### 🔁 **4. Scenario: Duplicate Record Removal**

**Scenario:** You’re given a large dataset with duplicate records. You want to remove duplicates efficiently.

**Question:** Describe a MapReduce strategy to achieve this.

**Answer:**

- **Map phase:** Emit (record, null) for each input record 📤.
    
- **Shuffle phase:** All duplicates are grouped together.
    
- **Reduce phase:** Emit only one instance of each record ➖.
    

🌟 Easy way to clean large datasets!

---

#### 📊 **5. Scenario: Top-K Frequent Products Sold**

**Scenario:** From a massive sales dataset, find the top 10 most frequently sold products.

**Question:** Explain a MapReduce approach to this.

**Answer:**

- **Map phase:** Emit (productID, 1) per sale.
    
- **Combiner:** Sum local counts 💡.
    
- **Reduce phase:** Sum global counts per product → emit (productID, total_sales) 🧾.
    
- **Post-process step (optional MapReduce):** Another job to sort and select top 10 💯.
    

🧠 You might sort results using a custom partitioner and reducer.

---

#### 🎯 **6. Scenario: Personalized Recommendations**

**Scenario:** You need to calculate how many times each user clicked on each product.

**Question:** How would you use MapReduce to generate user-product interaction counts?

**Answer:**

- **Map phase:** Emit ((userID, productID), 1) for each interaction 🔍.
    
- **Reduce phase:** Sum values for each (userID, productID) pair → emit ((userID, productID), count) 👤📦.
    

📈 Can be used as input to collaborative filtering models later.

---

#### ✨ Extra Tips for Answering Scenario Questions

When you see a MapReduce scenario:

1. **Break the data into key/value format** 🎯
    
2. **Describe what the Map function will emit** 🧠
    
3. **Explain the grouping logic in the shuffle phase** 🔃
    
4. **Describe how the Reduce function aggregates the results** ➕
    

👉 Always consider:

- **Data skew** (uneven keys) 🧮
    
- **Combiner usage** to reduce network load 🌐
    
- **Partitioning strategy** if data locality or grouping matters 📍


### **Question 1**

This question is based on MapReduce, Fundamentals of Distributed Systems, Linearizability, and Go Programming.

Assume that an ecommerce company is interested in finding the hit-counts of its products. Their web solution generates log files of customer hits in the format given below:
```
time_stamp customer_id product_id
```
It creates a new log file either after 10 million records or every three days, whichever comes first. The company is willing to investigate over ~600 files of the last 5 years.

**i.** Define the **Map function** with details and explain its functionality by stating any assumptions you made. (You can provide a Pseudo code if you may)

**ii.** Define the **Reduce function** and explain its functionality. (You can provide a Pseudo code if you may)

**iii.** Assume your Map function writes intermediate output to `intermediate-<map_task_file_id>.csv` in the file system that is shared by all the workers using only the following code snippet. This is done without writing to a temporary file in its local storage. Is there any issue with this implementation? If yes, explain in detail why. If not, defend why not.

**Go programming code:**

```
outputfile := fmt.Sprintf("intermediate-%d", map_task_file_id)
file_ := os.Create(outputfile)
//write data to file while running.map reduce
file.Close()
```
**iv.** Suggest any modification to the above code that can mitigate the issues you have mentioned above. (Skip if there is no issue identified; marks will be allocated to part iii.)

**v.** When investigating the task files, it was noticed that:

- Most files had less than 10 million records.
    
- Files with 10 million records (~1 GB in size) constituted about `1/3` of all files.
    
- `1/2` of the files were between `500 MB – 750 MB`.
    
- The rest were less than `500 MB`.
    

Comment on the **Master algorithm** that might best support load balancing and processing time, considering 10 homogeneous workers in a work pool.


### **📌 i. Map Function Definition & Explanation**

**🎯 Functionality**:  
The **Map** function processes each log entry to generate intermediate key-value pairs. For the e-commerce hit-count problem:

- **Input**: `(timestamp, customer_id, product_id)`
    
- **Output**: `(product_id, 1)` _(where `1` represents a single hit)_
    

**🔍 Assumptions**:  
✔ Each log line is well-formatted.  
✔ `product_id` is unique and suitable for aggregation.

**📜 Pseudo-Code**:
```
def Map(line):
    timestamp, customer_id, product_id = line.split()
    EmitIntermediate(product_id, "1")  # Emit (product_id, 1)
```
**📖 Explanation**:

- Parses each log line → extracts `product_id` → emits `(product_id, 1)` for counting.
    
- Follows the **MapReduce** model (Section 2 of the paper).
    

**🔗 Reference**:  
📄 _Paper Example_: Word counting (Section 2.1).

---

### **📌 ii. Reduce Function Definition & Explanation**

**🎯 Functionality**:  
Aggregates counts for each `product_id` to compute total hits.

**📜 Pseudo-Code**:
```
def Reduce(product_id, counts):
    total_hits = 0
    for count in counts:
        total_hits += int(count)
    Emit(product_id, total_hits)
```
**📖 Explanation**:

- Sums all `1`s for each `product_id`.
    
- Example: If `product_id=123` appears **5 times**, emits `(123, 5)`.
    

**🔗 Reference**:  
📄 _Paper Example_: Summing word counts (Section 2.1).

---

### **📌 iii. Analysis of Go Code for Intermediate Output**

**🚨 Issue Identified**:  
The provided Go code has **concurrency & fault-tolerance problems**:

1. **Race Condition** 🏎️: Multiple workers may write to the same file simultaneously → **data corruption**.
    
2. **No Atomicity** ⚡: If a worker crashes mid-write, the file is left **incomplete**.
    

**❌ Why It’s Bad**:

- The paper (Section 3.1) says workers should **first write locally**, then share outputs.
    
- Direct shared writes **bypass master coordination** (Section 3.2).
    

**🔗 Reference**:  
📄 _Paper_: Fault tolerance relies on atomic commits (Section 3.4).

---

### **📌 iv. Suggested Fix for Go Code**

**✨ Solution**:

1. **Write locally first** → Avoid concurrency issues.
    
2. **Use atomic rename** → Ensure consistency.
    

**🛠️ Improved Go Code**:
```
tempFile := fmt.Sprintf("/local/intermediate-%d.tmp", taskID)
file, err := os.Create(tempFile)
if err != nil {
    log.Fatal("Failed to create temp file:", err)
}
// Write data...
file.Close()
// Atomically rename to final location
finalFile := fmt.Sprintf("/shared/intermediate-%d.csv", taskID)
os.Rename(tempFile, finalFile)
```
**📖 Explanation**:  
✔ **Local writes** → No race conditions.  
✔ **Atomic rename** → File either fully exists or not at all.

**🔗 Reference**:  
📄 _Paper_: Atomic renames for fault tolerance (Section 3.5).

---

### **📌 v. Master Algorithm for Load Balancing**

**⚖️ Problem**:

- Files vary in size (**1GB**, **500-750MB**, **<500MB**).
    
- **10 workers** must process them efficiently.
    

**🚀 Optimal Strategy**:

1. **Dynamic Scheduling** 🔄:
    
    - Assign **largest files first** (1GB).
        
    - Use **backup tasks** (Section 3.8) for stragglers.
        
2. **Partitioning** ✂️:
    
    - Split big files into **64MB chunks** (like in the paper).
        
    - Assign chunks to idle workers.
        

**🔗 Reference**:  
📄 _Paper_:

- **Task granularity** (Section 3.6).
    
- **Backup tasks** reduce stragglers (Section 3.8).
    

---

### **🎯 Key Takeaways from the Paper**

1. **MapReduce Flow** → Map → Shuffle → Reduce.
    
2. **Fault Tolerance** → Re-execution + atomic commits.
    
3. **Locality Optimization** → Prefer workers with local data.
    
4. **Load Balancing** → Fine-grained tasks + backups.
    

These principles directly guide the answers above! 🚀

---

### **💡 Final Notes**

- **Concurrency** must be handled carefully (avoid shared writes).
    
- **Atomicity** is critical for fault tolerance.
    
- **Dynamic scheduling** ensures efficient processing.



## [[102. GFS]] and [[104. Raft]]

### **Question: Google File System, Consistency, Time Concepts, and Raft**

#### **i. Comment on the consistency promise of GFS in its original form.** [03 marks]

#### **ii. GFS with triple replica scenario:**

The system starts with the value **"5"** (one byte). Two clients perform operations concurrently:

**Client A:**

1. Writes **"4"** at offset 0 (replaces "5").
    
2. Upon successful completion, writes **"6"** at offset 0 (replaces "4").
    

**Client B:**

1. Performs **3 read operations**, displaying the file content each time.
    

**a.** Can Client B see **"5"** after seeing **"4"**? Explain why this is possible or restricted. [04 marks]

**b.** Can Client B see **"5"** after seeing **"6"**? Explain why this is possible or restricted. [04 marks]

#### **iii.** What modification to GFS would ensure **read-after-write consistency** for each client in this case? [05 marks]

#### **iv. Introducing Raft to reduce write latency:**

**a.** How can Raft achieve this? [03 marks]  
**b.** Discuss the consequences of this design change. [03 marks]  
**c.** What additional steps can mitigate these consequences? [03 marks]

### ***Answer***

#### **i. Comment on the consistency promise of GFS in its original form.** [03 marks]

🔹 **GFS Relaxed Consistency Model**  
The Google File System (GFS) provides a **relaxed consistency model** optimized for large-scale, append-heavy workloads. Unlike traditional file systems that guarantee strong consistency (all clients see the same data at the same time), GFS prioritizes **high throughput and fault tolerance** over strict consistency.

📌 **Key Points from the GFS Paper (Section 2.7):**

1. **Defined vs. Undefined Regions**
    
    - A file region is **defined** if all clients see the same data written by a successful mutation.
        
    - A region is **undefined but consistent** if concurrent mutations interleave, resulting in a mix of fragments.
        
    - Failed mutations leave regions **inconsistent** (different clients see different data).
        
2. **Append vs. Overwrite**
    
    - **Record appends** are atomic (at least once) but may include duplicates or padding.
        
    - **Writes** at explicit offsets are not atomic under concurrency.
        
3. **Replica Synchronization**
    
    - The primary replica serializes mutations, ensuring all replicas apply changes in the same order.
        
    - Stale replicas (missed updates) are garbage-collected.
        

🔹 **Why Relaxed Consistency?**

- GFS is designed for **batch processing** (e.g., MapReduce) where sequential reads dominate.
    
- Clients use techniques like **checksums** and **self-identifying records** to handle inconsistencies.
    

👉 **Conclusion:** GFS trades strict consistency for scalability and performance, relying on application-level checks to handle edge cases.

---

#### **ii. GFS Triple Replica Scenario**

**Scenario:**

- Initial value: "5" (1 byte).
    
- **Client A**:
    
    1. Writes "4" at offset 0 (replaces "5").
        
    2. Writes "6" at offset 0 (replaces "4").
        
- **Client B**: Reads the file 3 times during concurrent writes.
    

**a. Can Client B see "5" after seeing "4"?** [04 marks]  
✅ **Yes, it’s possible!** Here’s why:

1. **Replica Divergence**
    
    - GFS replicas may not sync instantly.
        
    - Client B might read from a replica that hasn’t yet applied the write("4") due to network delays.
        
2. **Stale Reads**
    
    - If Client B’s first read fetches "4" from an up-to-date replica but the second read hits a stale replica still holding "5", it observes **"4" → "5"**.
        
3. **No Read-After-Write Guarantee**
    
    - GFS does **not** guarantee linearizability. Clients caching chunk locations may see outdated data until the master updates metadata.
        

📌 **Reference (GFS Section 2.7.1):**

> "Clients cache chunk locations and may read from stale replicas before refreshing metadata."

---

**b. Can Client B see "5" after seeing "6"?** [04 marks]  
❌ **No, this is restricted!** Here’s why:

1. **Order of Writes**
    
    - Client A’s operations are serialized: write("4") → write("6").
        
    - Once "6" is written, all replicas **must** have applied "4" first (per primary’s ordering).
        
2. **No Time Travel**
    
    - A replica showing "5" after "6" would imply data corruption or a severe bug (e.g., missed mutations).
        
    - GFS detects stale replicas via **version numbers** and excludes them from serving reads.
        

📌 **Reference (GFS Section 4.5):**

> "Stale replicas are garbage-collected and never served to clients."

---

#### **iii. Achieving Read-After-Write Consistency** [05 marks]

To fix this, modify GFS to:

1. **Lease Extensions**
    
    - The master grants **longer leases** to primaries, reducing stale reads during write propagation.
        
2. **Client Cache Invalidation**
    
    - Force clients to **invalidate cached chunk locations** after writes (e.g., shorter TTLs).
        
3. **Synchronous Replication**
    
    - Make the primary wait for **all replicas** to acknowledge writes before replying to clients (at the cost of latency).
        
4. **Version Checks**
    
    - Clients include a **version token** in reads, ensuring they only get data ≥ their last write.
        

📌 **Reference (GFS Section 3.1):**

> "The primary sequences mutations and ensures all replicas apply them in order."

---

#### **iv. Raft for Reducing Write Latency**

**a. How Raft Helps** [03 marks]  
🚀 **Raft’s Optimizations:**

1. **Strong Leader**
    
    - All writes go through the leader, avoiding Paxos’s multi-round voting.
        
2. **Batched Appends**
    
    - The leader pipelines log entries to followers in **single RPCs** (vs. Paxos’s per-entry prepares).
        
3. **No Stale Reads**
    
    - Followers reject outdated writes, ensuring fast convergence.
        

📌 **Reference (Raft Section 5.3):**

> "Leaders optimize log replication by batching entries and retrying inconsistently."

---

**b. Consequences** [03 marks]  
⚠️ **Trade-offs:**

1. **Leader Bottleneck**
    
    - The leader handles all writes; if it’s slow, the cluster slows.
        
2. **Network Sensitivity**
    
    - Heartbeat delays can trigger unnecessary elections.
        
3. **Scalability Limits**
    
    - Larger clusters increase leader load.
        

---

**c. Mitigations** [03 marks]  
🛠 **Solutions:**

1. **Leader Stickiness**
    
    - Use **pre-voting** (Raft extension) to avoid flappy elections.
        
2. **Parallel Writes**
    
    - Shard data across multiple Raft groups (like Spanner).
        
3. **Hardware Tuning**
    
    - Deploy leaders on low-latency nodes.
        

📌 **Reference (Raft Section 9.3):**

> "Randomized election timeouts reduce split votes and improve stability."

---

#### **Final Answer Summary**

- GFS favors **throughput over strong consistency** but can be enhanced with leases/caching.
    
- Raft **reduces write latency** via leadership but requires careful tuning.
    
- Both systems exemplify **trade-offs in distributed design**! 🌐


## [[103. VMWare-FT]]

Assume that in order to improve availability, the VMWare FT is extended to **two backup state machine replicas** and implemented with an **atomic clock-synchronized setup**, where the primary and both replicas are exactly in sync.

**i.** How would this new design impact the performance of the system in general while the primary is non-faulty? **[04 marks]**

**ii.** Assume after committing some entries, one secondary replica has crashed. How should the new design address this problem without compromising the original consistency guarantee of the VMWare design? **[05 marks]**

**iii.** When the primary is faulty, suggest the mechanism that will ensure only one of the secondaries is guaranteed to be promoted as the primary. **[03 marks]**

**iv.** To reduce the overhead of communication, it was suggested to simplify the append for time inquiries (such as current time inquiries) by treating them deterministically, as the clocks are in exact sync. Comment on this approach. What might be the result? **[06 marks]**

**v.** Consider the Clock Synchronization effort the implementers had made in this design.

- **a.** Justify or criticize this design choice. **[03 marks]**
    
- **b.** Assuming that precise time is a must in both secondary and primary clocks, discuss a cost-effective and feasible clock synchronization mechanism as an extension to the VMWare design. **[04 marks]**

### ***Answer***
#### **i. Impact on Performance with Non-Faulty Primary**

**Answer:**  
Extending VMware FT to **two backup replicas** (instead of one) would **increase performance overhead** while the primary is non-faulty due to:

1. **Additional Logging Bandwidth**: The primary must send log entries to two backups instead of one, doubling the network traffic (Section 5.1, Table 1).
    
2. **Synchronization Delay**: The Output Rule (Section 2.2) requires acknowledgments from **both backups** before the primary can send external outputs, increasing latency.
    
3. **CPU Overhead**: The primary’s hypervisor must manage logging channels to two replicas, adding computational load (Section 5.1).
    

**Reference**:

- The paper notes that even with one backup, logging bandwidth is typically <20 Mbit/s (Table 1), but adding a second backup would scale this linearly.
    
- The Output Rule (Section 2.2) delays outputs until backups acknowledge logs; waiting for two replicas would exacerbate this delay.
    

---

#### **ii. Handling a Secondary Replica Crash Without Compromising Consistency**

**Answer:**  
To maintain consistency if one secondary crashes:

1. **Continue Logging to the Remaining Backup**: The primary switches to sending logs only to the surviving backup (Section 2.3).
    
2. **Atomic Commit Protocol**: Ensure the surviving backup has acknowledged all logs up to the crash point (Section 2.2, Output Rule).
    
3. **Restart Redundancy**: Use **FT VMotion** (Section 3.1) to spawn a new backup on another host, syncing its state with the primary.
    

**Reference**:

- The paper describes automatic redundancy restoration via FT VMotion (Section 3.1).
    
- The Output Rule guarantees consistency by ensuring backups replay all operations before outputs are sent (Section 2.2).
    

---

#### **iii. Promoting One Secondary When Primary Fails**

**Answer:**  
To ensure **only one secondary** becomes primary:

1. **Shared Storage Arbitration**: Use an atomic **test-and-set** operation on shared storage (Section 2.3). The first replica to succeed becomes primary; the other halts.
    
2. **Heartbeat Timeout**: If connectivity is lost, the backup with the lowest network latency/heartbeat response wins (Section 2.3).
    

**Reference**:

- The paper’s split-brain resolution relies on shared storage (Section 2.3): "Only one VM can win the test-and-set and go live."
    

---

#### **iv. Treating Time Inquiries as Deterministic**

**Answer:**  
**Pros**:

- **Reduced Logging**: Eliminates logging for clock reads, cutting bandwidth (Section 4.2).
    
- **Lower Latency**: No need to wait for backup acknowledgments for time queries.
    

**Cons**:

- **Clock Drift Risk**: Even atomic clocks can desynchronize, causing divergence (Section 2.1).
    
- **Non-Determinism**: If clocks drift, backups may replay incorrectly (e.g., timer interrupts at wrong instructions).
    

**Reference**:

- The paper highlights non-determinism from clock reads (Section 2.1).
    
- Deterministic replay requires logging all non-deterministic events (Section 2.1).
    

---

#### **v. Clock Synchronization Design**

**a. Justification/Criticism**  
**Answer**:

- **Justification**: Atomic sync ensures replicas replay interrupts at the same instruction, critical for determinism (Section 2.1).
    
- **Criticism**: Overhead of sync may outweigh benefits for non-time-sensitive workloads.
    

**b. Cost-Effective Sync Mechanism**  
**Answer**:  
Use **NTP with Hardware Assist**:

1. **NTP for Coarse Sync**: Low-cost, software-based synchronization.
    
2. **RDMA or PTP for Precision**: For sub-microsecond sync, use hardware-assisted protocols (e.g., Precision Time Protocol).
    

**Reference**:

- The paper assumes exact sync (Section 2.1) but doesn’t prescribe a method.
    
- Hardware counters (Section 2.1) could be extended for sync.
    

---

### **Key Takeaways from the Paper**

1. **FT Overhead**: Primarily from logging non-deterministic events (Section 2.1).
    
2. **Consistency**: Output Rule and shared storage prevent split-brain (Section 2.2–2.3).
    
3. **Redundancy**: FT VMotion automates backup recovery (Section 3.1).


## [[104. Raft]] and [[107. Bitcoin]]

### **Question 4:**

**i.** Comment on the possibility of applying Rafi implementation as the consensus mechanism for Bitcoin. **[03 marks]**

**ii.** Consider a real-life problem where a Bitcoin spender commits a transaction with a mistaken vendor ID by inserting it manually.  
**a.** Assume that the vendor ID included does not exist. How would this transaction be handled by Bitcoin? **[04 marks]**  
**b.** In contrast to the above, if the mistakenly entered vendor ID exists, what processes should be in the Bitcoin architecture to avoid this transaction being committed? **[05 marks]**

**iii.** Blockchain makes use of proof-of-work to validate the mining process.  
**a.** Comment on its advantages and disadvantages. **[03 marks]**  
**b.** Explain how it is improved with its successors like proof-of-stake and proof-of-authority. **[04 marks]**

**iv.** In the Bitcoin paper by Satoshi Nakamoto, it is suggested to randomly vary the number of leading zeros required in the hashed block to secure the blockchain design, and it is defined by the hardness level. Explain how this will adjust to an extremely dynamic mining effort. For instance, how can blockchain design keep the 10-minute commitment guarantee if a drastic reduction in the number of miners takes place? Or vice versa?


### **Answer:**

Applying **Raft** as a consensus mechanism for **Bitcoin** is **not feasible** due to fundamental differences in their design goals and operational models. Below are key reasons:

1. **Leader-Based vs. Leaderless Consensus**
    
    - **Raft** is a **leader-based** consensus algorithm where a single leader coordinates log replication and decision-making. This introduces a centralization risk, which contradicts Bitcoin’s **decentralized** peer-to-peer nature (_Bitcoin paper, Section 1_).
        
    - **Bitcoin** uses **Proof-of-Work (PoW)**, a **leaderless** system where any node can propose blocks, ensuring no single point of control (_Bitcoin paper, Section 4_).
        
2. **Finality vs. Probabilistic Consensus**
    
    - **Raft** provides **immediate finality** once a log entry is committed by a majority (_Raft paper, Section 5.3_).
        
    - **Bitcoin** uses **probabilistic finality**, where transactions are considered confirmed only after multiple blocks are mined on top of them (_Bitcoin paper, Section 11_).
        
3. **Performance and Scalability**
    
    - **Raft** is optimized for low-latency, high-throughput systems (e.g., distributed databases) but requires **fixed membership** and **strong synchronization** (_Raft paper, Section 5.2_).
        
    - **Bitcoin** prioritizes **permissionless participation** and **Byzantine fault tolerance**, allowing nodes to join/leave dynamically (_Bitcoin paper, Section 5_).
        
4. **Security Model**
    
    - **Raft** assumes **non-Byzantine failures** (nodes may crash but not act maliciously) (_Raft paper, Section 2_).
        
    - **Bitcoin** defends against **Sybil attacks** and **double-spending** via PoW and economic incentives (_Bitcoin paper, Section 6_).
        

**Conclusion:**  
Raft’s design is **unsuitable** for Bitcoin due to its **centralization risks, lack of Byzantine fault tolerance, and incompatibility with PoW**. Bitcoin’s **decentralized, adversarial model** requires a different approach (_Bitcoin paper, Section 12_).

---

### **(a) Assume that the vendor ID does not exist. How would this transaction be handled by Bitcoin? [04 marks]**

### **Answer:**

1. **Transaction Propagation**
    
    - The spender broadcasts the transaction to the Bitcoin network (_Bitcoin paper, Section 5_).
        
    - Nodes validate the transaction structure (signatures, inputs, outputs) but **cannot verify the recipient’s existence** since Bitcoin addresses are pseudonymous (_Bitcoin paper, Section 10_).
        
2. **Inclusion in Mempool**
    
    - Valid transactions are stored in the **mempool** (pending transactions pool) of nodes (_Bitcoin paper, Section 5_).
        
3. **Mining and Block Inclusion**
    
    - Miners select transactions from the mempool to include in a block (_Bitcoin paper, Section 6_).
        
    - Since the **vendor ID (address) does not exist**, the transaction is still processed because Bitcoin does not validate recipient activity.
        
4. **Final Outcome**
    
    - The transaction is **irreversible once confirmed** (added to the blockchain).
        
    - The funds are **lost forever** because no one controls the invalid address (_Bitcoin paper, Section 7_).
        

### **(b) If the mistakenly entered vendor ID exists, what processes should be in the Bitcoin architecture to avoid this transaction being committed? [05 marks]**

### **Answer:**

Bitcoin’s architecture **cannot prevent** accidental payments to valid addresses, but the following mechanisms help mitigate risks:

1. **Address Checksum Validation**
    
    - Bitcoin addresses include a checksum (Base58 encoding) to detect typos (_Bitcoin paper, Section 2_).
        
    - Wallets reject malformed addresses before broadcasting.
        
2. **Human-Readable Addresses (Bech32, ENS)**
    
    - Modern wallets support **Bech32 (SegWit)** and **ENS (Ethereum Name Service)** for error-resistant addresses.
        
3. **Double-Confirmation Prompts**
    
    - Wallets can **warn users** if a recipient address is new/unusual.
        
4. **Multi-Signature Escrow**
    
    - Businesses can use **multi-sig wallets** requiring multiple approvals before funds are released (_Bitcoin paper, Section 1_).
        
5. **Transaction Replace-by-Fee (RBF)**
    
    - If the transaction is unconfirmed, the sender can **replace it** with a corrected version (_Bitcoin paper, Section 5_).
        

**Conclusion:**  
Bitcoin’s **trustless model** means transactions **cannot be reversed**, but wallet-level safeguards reduce errors (_Bitcoin paper, Section 12_).

---
### **(a) Comment on its advantages and disadvantages. [03 marks]**

### **Answer:**

|**Advantages**|**Disadvantages**|
|---|---|
|**1. Security:** PoW ensures resistance to Sybil and 51% attacks (_Bitcoin paper, Section 4_).|**1. Energy Intensive:** High computational power required (_Bitcoin paper, Section 6_).|
|**2. Decentralization:** No single entity controls mining (_Bitcoin paper, Section 5_).|**2. Slow Transactions:** ~10 min block time (_Bitcoin paper, Section 5_).|
|**3. Fair Distribution:** Miners compete openly for rewards (_Bitcoin paper, Section 6_).|**3. Centralization Risk:** Mining pools dominate (_Bitcoin paper, Section 11_).|

### **(b) Explain how it is improved with its successors like proof-of-stake and proof-of-authority. [04 marks]**

### **Answer:**

1. **Proof-of-Stake (PoS)**
    
    - **Energy Efficiency:** Validators are chosen based on **staked coins**, not computational work (_Ethereum’s Casper FFG_).
        
    - **Faster Finality:** Shorter block times (~12 sec in Ethereum 2.0).
        
    - **Economic Security:** Attackers lose staked funds if malicious (_Bitcoin paper, Section 6_ analogy).
        
2. **Proof-of-Authority (PoA)**
    
    - **Permissioned Model:** Only approved validators (e.g., enterprises) can produce blocks (_Raft-like leader selection_).
        
    - **High Throughput:** Suitable for private blockchains (e.g., Hyperledger).
        

**Conclusion:**  
PoS and PoA address PoW’s **energy waste** and **scalability issues** but trade off **decentralization** (_Bitcoin paper, Section 12_).

---
### **Answer:**

Bitcoin’s **difficulty adjustment algorithm** ensures **consistent block times** despite fluctuating hash power (_Bitcoin paper, Section 4_):

1. **Target Block Time:** 10 minutes (set in protocol).
    
2. **Difficulty Recalculation:** Every **2016 blocks** (~2 weeks), the network adjusts difficulty based on:
    
    New Difficulty=Old Difficulty×Actual TimeExpected Time (2016 blocks × 10 min)New Difficulty=Old Difficulty×Expected Time (2016 blocks × 10 min)Actual Time​
3. **Hash Rate Impact:**
    
    - If **more miners join**, blocks are found faster → difficulty **increases**.
        
    - If **miners leave**, blocks slow down → difficulty **decreases**.
        
4. **Self-Correcting Mechanism:**
    
    - Ensures **long-term stability** of the blockchain (_Bitcoin paper, Section 4_).
        

**Example:**

- If blocks are mined in **8 min** on average, difficulty increases by **25%** to restore 10 min.
    

**Conclusion:**  
This mechanism maintains **network security** and **predictable coin issuance** (_Bitcoin paper, Section 6_).

---

### **Final Notes:**

- **Raft** is for **permissioned, crash-fault-tolerant** systems (_Raft paper, Section 2_).
    
- **Bitcoin** is for **permissionless, Byzantine-fault-tolerant** systems (_Bitcoin paper, Section 1_).
    
- **References:** Direct citations from both papers support each answer.